{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Unit 7</h1> </center>\n",
    "<center> <h1>Feature engineering</h1></center>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<center> <h3>IST 718 â€“ Big Data Analytics</h3> </center>\n",
    "<center> <h3>Daniel E. Acuna</h3> </center>\n",
    "<center> <h3>http://acuna.io</h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature engineering\n",
    "- From Wikipedia:\n",
    "<div class=\"blockquote2\">\n",
    "  <p>Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work.</p>\n",
    "</div>\n",
    "\n",
    "- \"Work\" can mean a number of things:\n",
    "  - Algorithm **converges faster**.\n",
    "  - Algorithm finds **better fits** to the training data.\n",
    "  - Algorithm find more **generalizable** solutions.\n",
    "  - Algorithm find more **interpretable** solutions.\n",
    "  \n",
    "- With feature engineering, we try to achieve all these things together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An example\n",
    "- The Titanic disaster: British passenger liner that sank in the North Atlantic Ocean in 1921.  \n",
    "\n",
    "- We have the dataset of the passengers and whether they survived or not.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe1.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The raw data\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe2.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The raw data (2)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe3.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Most algorithms work with numerical representations\n",
    "We only have a handful of numerical features:\n",
    "<div class=\"container2\">\n",
    "  <div class=\"row2\">\n",
    "    <div class=\"col-6\">\n",
    "        <ul>\n",
    "          <li>pclass (1, 2, or 3)</li>\n",
    "          <li>survived (0 or 1)</li>\n",
    "          <li>age: double</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-6\">\n",
    "        <ul>\n",
    "          <li>sibsp: integer</li>\n",
    "          <li>parch: integer</li>\n",
    "          <li>fare: double</li>        \n",
    "        </ul>\n",
    "    </div>\n",
    " </div>\n",
    "</div>\n",
    "\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe4.png\" width=\"95%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An initial model\n",
    "\n",
    "$$p(\\text{survived}=1)=f(\\text{pclass},\\text{age},\\text{sibsp}, \\text{parch},\\text{fare})$$\n",
    "\n",
    "- AUC = 0.75  \n",
    "\n",
    "- Parameters:\n",
    "  - Intercept: 2.8\n",
    "  - Coefficients: [-0.9888, -0.0377, -0.269, 0.2647, 0.0029]  \n",
    "  \n",
    "- Interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems with initial model\n",
    "<br>\n",
    "Weights are in different dimensions:\n",
    "- Bad for optimization: why?  \n",
    "\n",
    "- Bad for interpretation: why?  \n",
    "\n",
    "- Bad for regularization: why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-07/unit-07-1_fe5.png\" width=\"65%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling: Standardization\n",
    "\n",
    "- Make the data distributed according to a Gaussian distribution with mean 0 and standard deviation 1.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe6.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An initial model on standardized data\n",
    "\n",
    "$$p(\\text{survived}=1)=f(\\text{pclass},\\text{age},\\text{sibsp},\\text{parch},\\text{fare})$$\n",
    "\n",
    "- AUC = 0.75 (same)  \n",
    "\n",
    "- Parameters:\n",
    "  - Intercept: -0.4\n",
    "  - Coefficients: [-0.8346, -0.5404, -0.244, 0.2177, 0.1636]  \n",
    "  \n",
    "- Interpretation is easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other forms of scaling\n",
    "- Min--Max Scaling: transform a feature to be between 0 and 1.\n",
    "- **Warning**: it shifts the features and therefore destroys sparsity.  \n",
    "\n",
    "$$\\text{Rescaled}(e_i)=\\frac{e_i-E_\\text{min}}{E_\\text{max}-E_\\text{min}}(\\text{max}-\\text{min})+\\text{min}$$  \n",
    "\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe7.png\" width=\"95%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other forms of scaling (2)\n",
    "- Max Absolute Scaling: transform a feature to be between -1 and 1.\n",
    "- It does not destroy sparsity.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe7.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deal with non-normal distributions\n",
    "- Sometimes we have data that varies wildly.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe8.png\" width=\"80%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deal with non-normal distributions: Bucketizer\n",
    "- Split variables into multiple buckets based on predefined splits.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe9.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deal with non-normal distributions: Quantizer\n",
    "- Split variables into multiple buckets based on quantiles: guarantee that buckets contain same number of datapoints.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe10.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dummy variables for binary variables\n",
    "- A categorical variable with 2 possibilities generates 1 dummy variable.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe11.png\" width=\"40%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dummy variables\n",
    "- When a variable represents categories:  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe12.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Full example\n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe13.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pyspark_pipes\n",
    "- Optional package created by professor Acuna:  \n",
    "  https://github.com/daniel-acuna/pyspark_pipes  \n",
    "\n",
    "- It simplifies\n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe14.png\" width=\"90%\" align=\"center\"></center>\n",
    "<br>\n",
    "  into\n",
    "<br>\n",
    "<center><img src=\"./images/unit-07/unit-07-1_fe15.png\" width=\"60%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Full example: transformers\n",
    "- Term frequency:  \n",
    "  `Tokenizer` or `RegexTogenizer` -> `CountVectorizer`  \n",
    "  \n",
    "- Dummy variable (from number):  \n",
    "  `OneHotEncoder`  \n",
    "  \n",
    "- Dummy variable (from string):  \n",
    "  `StringIndexer` -> `OneHotEncoder`  \n",
    "  \n",
    "- Quantilization:  \n",
    "  `QuantileDiscretizer`  \n",
    "  \n",
    "- Arbitrary SQL Transformation:  \n",
    "  `SQLTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross validation\n",
    "- `CrossValidator` sweeps through set of parameters and estimates generalization performance with cross validation.\n",
    "  - `Estimator`: Pipeline with ML model.\n",
    "  - `estimatorParamMaps`: set of parameters to try.\n",
    "  - `Evaluator`: loss function for choosing best one.\n",
    "  - `numFolds`: number of folders.  \n",
    "  \n",
    "- Final AUC = 0.90  \n",
    "\n",
    "- How to intercept the parameters?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
