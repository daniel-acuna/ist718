{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <h1>Unit 1.1</h1> </center>\n",
    "<center> <h1>Basics linear algebra, probability, calculus</h1> </center>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<center> <h3>IST 718 – Big Data Analytics</h3> </center>\n",
    "<center> <h3>Daniel E. Acuna</h3> </center>\n",
    "<center> <h3>http://acuna.io</h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scalars\n",
    "\n",
    "- Represented by Greek letters $\\alpha, \\beta, \\gamma$\n",
    "- Represent numbers\n",
    "- $\\alpha = 0.1, \\beta = 1^{-10}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notation and simple matrix algebra\n",
    "\n",
    "- We let $\\textbf X$ denote a $n \\times p$ matrix whose $(i,j)$th element is $x_{ij}$. That is,  \n",
    "\n",
    "$$\\textbf X = \\begin{bmatrix} x_{11}&x_{12}&\\cdots&x_{1p}\\\\ x_{21}&x_{22}&\\cdots&x_{2p}\\\\ \n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\ x_{n1}&x_{n2}&\\cdots&x_{np}\\\\ \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "- $\\textbf X$ can be visualize as a spreadsheet of numbers with $n$ rows and $p$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The rows of $\\textbf X$ can be written as $x_1, x_2,...,x_n$. Here $x_i$ is a vector of lenght $p$, containing the $p$ variable measurements for the $i$th observation. That is,  \n",
    "\n",
    "$$x_i = \\begin{pmatrix} x_{i1}\\\\ x_{i2} \\\\ \\vdots\\\\ x_{ip}\\\\ \\end{pmatrix}$$\n",
    "\n",
    "- IMPORTANT: vectors are by default represented as columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The columns of $\\textbf X$ can written as $x_1, x_2,...,x_p$. Each is a vector of length $n$. That is,  \n",
    "\n",
    "$${\\scriptsize \\textbf X_j} = \\begin{pmatrix} x_{1j}\\\\ x_{2j} \\\\ \\vdots\\\\ x_{nj}\\\\ \\end{pmatrix}$$\n",
    "\n",
    "\n",
    "$\\quad$ Using the previous notation, the matrix $\\textbf X$ can be written as  \n",
    "\n",
    "$\\qquad\\qquad$\n",
    "$\\textbf X = \\begin{pmatrix} {\\scriptsize \\textbf X_1}&{\\scriptsize \\textbf X_2}&\\cdots&{\\scriptsize \\textbf X_p}\\\\ \\end{pmatrix}$\n",
    "$\\qquad$or$\\qquad$\n",
    "$\\textbf X = \\begin{pmatrix} x_1^T\\\\ x_2^T \\\\ \\vdots\\\\ x_n^T\\\\ \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\;^T\\;$ notation denotes the *transpose* of a matrix or vector. So, for example,\n",
    "\n",
    "$$\\textbf X^T = \\begin{bmatrix} x_{11}&x_{21}&\\cdots&x_{n1}\\\\ x_{12}&x_{22}&\\cdots&x_{n2}\\\\ \n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\ x_{1p}&x_{2p}&\\cdots&x_{np}\\\\ \\end{bmatrix}$$  \n",
    "\n",
    "while  \n",
    "\n",
    "$$x_i^T = \\begin{pmatrix} x_{i1}&x_{i2}&\\cdots&x_{ip}\\\\ \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We use $y_i$ to denote the $i$th observation of the variable on wish we wish to make predictions. Hence we write the set of all $n$ observations in *vector form* as  \n",
    "\n",
    "$$\\textbf y = \\begin{pmatrix} y_1\\\\ y_2 \\\\ \\vdots\\\\ y_n\\\\ \\end{pmatrix}$$\n",
    "\n",
    "- Then our observed data consist of $\\{(x_1,y_1), (x_2,y_2),...,(x_n,y_n)\\}$, where each $x_i$ is a vector of length $p$.\n",
    "- If $p=1$, then $x_i$ is simply a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In this course, a vector of length $n$ will always be denoted in *lower case bold;* e.g.  \n",
    "\n",
    "$$\\textbf a = \\begin{pmatrix} a_1\\\\ a_2 \\\\ \\vdots\\\\ a_n\\\\ \\end{pmatrix}$$\n",
    "\n",
    "- However, vectors that are not of length $n$ (e.g., $x_i$) will be denoted in *lower case*. The same rule applies to scalars (e.g., $a$).\n",
    "\n",
    "- Matrices will be denoted using *bold capitals*, such as **$\\textbf X$**\n",
    "- Random variables will be denoted using capitals, e.g. $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix\n",
    "- Sometimes, we can define a matrix by its components as follows\n",
    "$\\textbf A=(f(i,j))_{ij}$ where $f(i, j)$ is a function of $i$ and $j$.\n",
    "- **For example**, define the matrix \n",
    "$$\\textbf X = \n",
    "\\begin{bmatrix} \n",
    "1 & 1 & \\cdots & 1\\\\ \n",
    "0 & 1 & \\cdots & 1\\\\ \n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\ 0& 0 & \\cdots & 1\\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "using a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix operations\n",
    "- Scalar times matrix: $\\alpha \\textbf A=(\\alpha \\times a_{ij} )_{ij}$\n",
    "- Matrix addition: $\\textbf A + \\textbf B $ (add each element one at a time)\n",
    "- Matrix multiplication: $\\textbf A \\textbf B$ ($\\text{#cols}_A = \\text{#rows}_B$)\n",
    "$$\\textbf A \\textbf B=\\left(\\sum_{z} a_{iz} b_{zj}\\right)_{ij}$$\n",
    "- Matrix transposition: make rows the columns\n",
    "$$\\textbf{A}^T=(a_{ij} )_{ji}$$\n",
    "- Many operations can be easily written as matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Special matrices and properties\n",
    "\n",
    "- Identity matrix (diagonal values are 1, everything else is 0)\n",
    "- $I = \\begin{bmatrix} 1&\\cdots&0\\\\ \\vdots&\\ddots&\\vdots\\\\ 0&\\cdots&1\\\\ \\end{bmatrix}$\n",
    "- Matrix inverse: $AA^{−1}=I$\n",
    "- Matrix addition is commutative: $A + B = B + A$\n",
    "- Matrix multiplication is NOT commutative: $AB \\neq BA$\n",
    "- $(AB)^T=B^T A^T$\n",
    "- Other matrix properties https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dimension\n",
    "\n",
    "To indicate that an object is:\n",
    "- a scalar, we will use the notation $a \\in \\mathbb{R}$  \n",
    "- a vector of length $n$, we will use $\\textbf a \\in \\mathbb{R^n}$  \n",
    "- a vector of length $k$, we will use $a \\in \\mathbb{R^k}$  \n",
    "- a $r \\times s$ matrix, we will use $\\textbf A \\in \\mathbb{R}^{r \\times s}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpreting graphs (1)\n",
    "- Equation of the line: intercept, slope\n",
    "  - Interpreting intercept and slope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Application:\n",
    "  -  Model 1: $\\widehat{income}=f(age)= 20000+5000 \\times age$\n",
    "  - The unit of the intercept is different from the unit of the slope\n",
    "  - Using matrix notation to make predictions for $age = \\{20, 25, 40\\}$<p>\n",
    "  - Represent model as a vector $b = \\begin{pmatrix} 20000\\\\ 5000\\\\ \\end{pmatrix}$\n",
    "  - Represent data as matrix $X =?$\n",
    "  - Making predictions: $X \\times b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpreting graphs (2)\n",
    "\n",
    "- Model 2:\n",
    "$$\\widehat{income}=f(age)= 20000+5000 \\times age + 10000 \\times education$$\n",
    "- Represent model 2 as a matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models (3)\n",
    "\n",
    "- Model: \n",
    "$$y=b_0+\\sum{b_j x_j}$$\n",
    "- Parameters of the model $b$\n",
    "- Data: set of features $X$ and outputs or targets $y$\n",
    "- One of the simplest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning as optimization\n",
    "- Let’s assume a simple model where we are trying to predict income\n",
    "$$\\widehat{income} = f() = b_0$$\n",
    "- This model does not take any features or inputs\n",
    "- We would like to find the $b_0$ to predict well the following data $income = \\{30000, 40000, 30000\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We usually define a **loss function** and a common loss function is squared or quadratic error \n",
    "$$ (\\widehat{income} − income)^2 $$\n",
    "- How do we find the right parameters for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning as optimization (2)\n",
    "- Define the loss as a function of the model's parameters and we try to minize it\n",
    "$$\\widehat{\\Theta} = \\arg \\min_\\Theta L(\\Theta)$$\n",
    "- How would this loss function look like for the model $\\widehat{income} = b_0$, data $income = \\{30000, 40000, 30000\\}$, and squared loss?\n",
    "- How to optimize it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization\n",
    "- We can find a minimum or maximum of a function by looking at the slope\n",
    "- Finding the minimum of a function:\n",
    "$$\\frac{df(x)}{dx}=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In multiple dimensions it is called a gradient:\n",
    "$$g = {\\begin{pmatrix} \\frac{df(x_1)}{dx_1} \\frac{df(x_2)}{dx_2} \\cdots \\frac{df(x_p)}{dx_p}\\\\ \\end{pmatrix}}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Derivatives\n",
    "- Definition of the derivative:\n",
    "$$\\frac{df(x)}{d(x)} \\approx \\lim\\limits_{\\Delta x \\to 0} {\\frac {f(x+\\Delta x)-f(x)}{\\Delta x}}$$\n",
    "- This means: the infinitesimal change in the function as the change is taken to zero\n",
    "- Take as examples:\n",
    "  - $𝑓_1(x) = a + xb$\n",
    "  - $𝑓_2(x) = x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization for model fitting\n",
    "- Model: $\\widehat{age}=b$\n",
    "- Data: $ages = \\{20, 25, 40\\}$\n",
    "- Function to minimize with quadratic errors?\n",
    "- Optimal value for $b$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other common derivation rules\n",
    "- Chain rule:\n",
    "$${\\textstyle \\frac{dg(f(x)}{dx}= \\frac{dg(f)}{f}\\frac{df(x)}{x}}$$  \n",
    "- Exercise, combine the following  rules: \n",
    "\n",
    "  (1) $\\frac{d(cf(x))}{dx}= c\\frac{df(x)}{dx}$   \n",
    "  \n",
    "  (2) $\\frac{d(f(x)+g(x))}{dx}=\\frac{d(f(x))}{dx}+\\frac{g(g(x))}{dx}$   \n",
    "  \n",
    "  (3) $\\frac{d(x^n)}{dx}=nx^{n-1}$  \n",
    "  \n",
    "  to solve ${\\textstyle \\frac{d(5x-\\mu)^3}{d𝑥}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common properties\n",
    "- ${\\displaystyle \\frac{d(e^x)}{dx}= e^x}$\n",
    "\n",
    "- ${\\displaystyle \\frac{d(\\log(x))}{dx}=\\frac{1}{x}}$\n",
    "\n",
    "- A common prediction function for probability values is the sigmoid:\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{−z}}$$\n",
    "\n",
    "\n",
    "- Use the properties learned before to calculate\n",
    "${\\displaystyle \\frac{d(\\sigma(z))}{𝑧}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A more complicated loss function\n",
    "- Logistic regression has a loss function called *cross-entropy*:\n",
    "$$l(z) = -y\\log(\\sigma(z)) - (1−y)\\log⁡(1−\\sigma(z))$$\n",
    "- Calculate\n",
    "${\\; \\displaystyle \\frac{dl(z)}{dz}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability\n",
    "- There are some phenomena which are not certain and therefore need a set of tools to still work with them\n",
    "- Probability deals with the likelihood or chance that an event will occur, and can deal with these phenomena\n",
    "- Several interpretation of what a likelihood is\n",
    "  - Frequency: the relative frequency of how many times an event occurs if the same conditions are repeated many times. E.g., if I flip a coin 5M times, what is the relative frequency of heads?\n",
    "  - Subjective definition: subjects have beliefs about the probability of an outcome which must be updated with certain consistent rules. E.g.: I may assume I will see heads 50% of the time, but I will update my belief if I see tails 10 times in a row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments and events\n",
    "- An experiment is any process for which the outcome is unknown\n",
    "- E.g.,:\n",
    "  - Experiment to estimate, out of 10 coin tosses, the number of times heads will be obtained\n",
    "  - If a spark job is running on 100 computers,  estimate the probability that the job will finish successfully if all computers must finish without error\n",
    "  - If I estimate that the average age of my data is 30 years, how likely is it to see someone 60 years old in the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Set theory\n",
    "- The collection of all possible outcomes in an experiment is called  *sample space*\n",
    "- For example:\n",
    "  - The *sample space* of an experiment with a dice could be<br>$S = \\{1, 2, 3, 4, 5, 6\\}$\n",
    "  - The event $A$ that an even number is obtained is defined by<br> $A = \\{2, 4, 6\\}$\n",
    "- Operations of set theory:\n",
    "  - Union\n",
    "  - Intersection\n",
    "  - Complement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability\n",
    "- Axioms:\n",
    "  1. Probability of any event is greater or equal to zero  \n",
    "  $p(A) \\geq 0$\n",
    "  2. If an event $S$ is certain to occur, then  \n",
    "  $p(S) = 1$\n",
    "  3. The probability of an infinite number of independent events $A, B, C,\\ldots$ is the sum of the probability of each event  \n",
    "  $p(A) + p(B) + p(C) + \\ldots$  \n",
    "\n",
    "\n",
    "- Any function that follows Axioms 1, 2, and 3 is a *probability distribution*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some derived properties (1)\n",
    "- For event $A$,  \n",
    "$p(\\lnot{A}) = 1 - p(A)$, proof?  \n",
    "<!--- \\big parentesis; \\bar \\lnot \\neg negar-->\n",
    "- For any two events $A$ and $B$,  \n",
    "$p(A \\cup B) = p(A) + p(B) - p(A \\cap B)$  \n",
    "\n",
    "- Conditional probability (probability of an event knowing that another event is certain)  \n",
    "$p(A \\mid B) = P(A \\cap B) / P(B)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some exercises\n",
    "1. A ball is selected from an urn with red, blue, and green balls. If the probability of red is $^1/_5$ and blue is $^2/_5$, what is the probability of getting a green ball?\n",
    "\n",
    "1. You toss 2 die\n",
    "   - What is the probability that sum of the die is 4?\n",
    "   - If I pay you one dollar for a 1 or 6. How much money are you expected to receive?\n",
    "1. A friend tells you that she has two children. You see one children and it is a girl. \n",
    "   - What is the probability that the other child is **also** a girl? \n",
    "   - What is the probability that the other child is a girl?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random variables and probability distributions\n",
    "- A random variable is a real-valued function that is defined on a sample space of an experiment\n",
    "- For example, a function defined over the number of heads after 5 tosses is a random variable. For sample $s = HHTTH$, the random variable would be $X(s) = 3$\n",
    "- The distribution of a random variable $X$ is the probability of the events underlying the random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrete and continuous random variables\n",
    "- If the random variable $X$ can take on a finite number of $k$ different values $x_1, ... x_k$ or, an infinite sequence of them, $X$ is a *discrete random variable*\n",
    "- Random variables that can take on every value on an interval are *continuous random variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrete probability distribution\n",
    "- Describes the probability of each real value $x$ of a discrete random variable\n",
    "$$ p(X = x)$$\n",
    "sometimes denoted simply as $p(x)$\n",
    "- The set of points such that $\\{ x\\mid p(x) > 0 \\}$ is denoted the *support* the probability distribution\n",
    "- The sum of all events must sum up to 1: $\\sum_x p(x) = 1$\n",
    "- $p$ is also call a *probability mass function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example of discrete probability distributions\n",
    "- Bernoulli distribution (probability of tossing head)\n",
    "$$p(X = H) = p(H) = \\theta $$\n",
    "and since the probability of all events must sum up to one $p(H) + p(T) = 1$ then $$p(T) = 1 - \\theta$$\n",
    "- This can be compactly represented as\n",
    "$$p(x) = \\theta^x (1-\\theta)^{1-x}$$ \n",
    "if we consider heads as 1 and tails as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example of discrete probability distributions (2)\n",
    "- Uniform distribution between integers $a$ and $b$ would be\n",
    "$$p(x) = \\begin{cases}\n",
    "\\frac{1}{b - a + 1} & a \\leq x \\leq b\\\\\n",
    "0 & \\text{o.w.}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continous probability distribution\n",
    "- Defines probabilities for bounded closed intervals $[a,b]$\n",
    "$$p(a \\leq X \\leq b) = \\int_a^b p(x) dx$$\n",
    "\n",
    "- $p(x) \\geq 0$ for all $x$\n",
    "- $\\int_{-\\infty}^{\\infty}p(x) = 1$\n",
    "- A single point in a continuous distribution has probability 0\n",
    "- $p$ is called a *probability density function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example of a continous distribution\n",
    "- Uniform distribution on an interval\n",
    "$$ p(x) = \\begin{cases}\n",
    "\\frac{1}{b - a} & a \\leq x \\leq b\\\\\n",
    "0 & \\text{o.w.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example of a continous distribution (2)\n",
    "- Sometimes we define probabilities without worrying about whether they sum up to 1\n",
    "$$ p(x) \\propto \\begin{cases}\n",
    "4 x & 0 \\leq x \\leq 1\\\\\n",
    "0 & \\text{o.w.}\n",
    "\\end{cases}$$\n",
    "- How to properly define the previous probability distribution? Hint: Use the fact that $\\int p(x) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Example of continous distribution (3)\n",
    "- Gaussian distribution\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left(-\\frac{1}{2 \\sigma^2}(x-\\mu)^2\\right)$$\n",
    "- $\\mu$ is called the mean and $\\sigma$ is called the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common statistics\n",
    "- Expectation: A *fancy average*\n",
    "$$E[f(x)] = \\sum_x p(x) f(x) \\quad E[f(x)] = \\int_x p(x) f(x) dx $$\n",
    "- Variance: *Spread*\n",
    "$$Var[f(x)] = E[ (f(x) - E[f(x)])^2 ]$$\n",
    "- Covariance: *Co-spread*\n",
    "$$Cov(f(x), g(y)) = E[(f(x) - E[f(x)])(g(y) - E[g(y)])]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Be careful: transformations of probability distributions\n",
    "$$\\begin{align} \n",
    "p(x) &\\propto \\begin{cases}\n",
    "1 & -\\frac{1}{2} \\leq x \\leq \\frac{1}{2}\\\\\n",
    "0 & \\text{o.w.}\n",
    "\\end{cases}\\\\\n",
    "y &= x^2\n",
    "\\end{align}$$\n",
    "- what is $E[x]$?\n",
    "- what is $E[y]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Joint distributions\n",
    "- The joint distribution of a set of random variables\n",
    "$$p(X_1 \\in C_1, X_2 \\in C_2, \\dots, X_k \\in C_k)$$\n",
    "can be read as the probability that the random variables are simultaneously in the intervals $C_1, \\dots, C_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Marginal probability\n",
    "\n",
    "- From a simple example distribution \n",
    "$$p(X_1 \\in C_1, X_2 \\in C_2)$$\n",
    "we can obtain the following \n",
    "$$p(X_1 \\in C_1) = \\sum_{x_2 \\in C_2} p(X_1 = x_1, X_2 = x_2)$$\n",
    "for a discrete distribution, and\n",
    "$$p(X_1 \\in C_1) = \\int_{x_2 \\in C_2} p(X_1 = x_1, X_2 = x_2) dx_2$$\n",
    "for a continous distribution.\n",
    "- This can be generalized for many variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional probability\n",
    "\n",
    "- If we did not have uncertainty about the value of random variable $X_2$, we write\n",
    "$$p(X_1 \\in C_1 \\mid X_2 \\in C_2) = \\frac{p(X_1 \\in C_1 , X_2 \\in C_2)}{p(X_2 \\in C_2)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Independence\n",
    "- If two random events are independent (they don't depend on each other), their joint probability can be expressed as the factor of their distributions\n",
    "$$p(X_1 \\in C_1,  X_2 \\in C_2) = p(X_1 \\in C_1) p(X_2 \\in C_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some exercises\n",
    "- You toss 2 die\n",
    "   - If I pay you one dollar for each and 1 or 6. What is expected value you are expected to receive?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
